{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bc1c020",
   "metadata": {},
   "source": [
    "# ___\n",
    "\n",
    "# [ Machine Learning in Geosciences ]\n",
    "\n",
    "**Department of Applied Geoinformatics and Carthography, Charles University** \n",
    "\n",
    "*Lukas Brodsky lukas.brodsky@natur.cuni.cz*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aa4340",
   "metadata": {},
   "source": [
    "# DEMO1: Nonlinear regression with high capacity ANN model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deb5e28",
   "metadata": {},
   "source": [
    "This notebook demonstrate how to deal with high capcity ANN model in case of low numbner of noisy samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91716316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1df096dddf0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84ec06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate nonlinear data\n",
    "X = np.linspace(-3, 3, 30).reshape(-1, 1)\n",
    "y = 2 * X**2 + X + np.random.normal(0, 3, X.shape)\n",
    "\n",
    "# Introduce multiple strong outliers\n",
    "outlier_indices = [2, 5, 7, 8, 9]\n",
    "outlier_values = [7, -6, 15, -11, 15]\n",
    "for i, idx in enumerate(outlier_indices):\n",
    "    y[idx] += outlier_values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b397b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, y, color='black', label=\"Data\", zorder=3)\n",
    "plt.legend()\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d17cb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "# (X - X.mean()) / X.std()\n",
    "X_train = torch.tensor(X, dtype=torch.float32)\n",
    "y_train = torch.tensor(y, dtype=torch.float32).reshape(-1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a6372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ANN model\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layers=[512, 256, 128, 64]):\n",
    "        super(ANN, self).__init__()\n",
    "\n",
    "        # Create hidden layers dynamically\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        for size in hidden_layers:\n",
    "            layers.append(nn.Linear(prev_size, size))\n",
    "            layers.append(nn.ReLU())  \n",
    "            prev_size = size\n",
    "        \n",
    "        layers.append(nn.Linear(prev_size, 1))  # Output layer\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3359ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model with optional regularization\n",
    "def train_model(model, X, y, epochs=2000, lr=0.005, batch_size=5):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X, y)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(batch_X)\n",
    "            loss = criterion(y_pred, batch_y)\n",
    "            # Backpropagation \n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de396f0d",
   "metadata": {},
   "source": [
    "### High capcity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2e624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = [32] * 5\n",
    "model_hc = ANN(hidden_layers=hidden_layers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187cac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "train_model(model_hc, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03ed34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "X_pred = torch.linspace(-3.5, 3.5, 100).reshape(-1, 1)\n",
    "with torch.no_grad():\n",
    "    y_pred_hc = model_hc(X_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e227f8ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, y, color='black', label=\"Data\", zorder=3)\n",
    "plt.plot(X_pred, y_pred_hc, label=\"ANN model\", linestyle='dotted', color='red', linewidth=2)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"High capcity ANN model prediction\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b61f7f8",
   "metadata": {},
   "source": [
    "### Low capacity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc98a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "hidden_layers = [1] * 2\n",
    "model_lc = ANN(hidden_layers=hidden_layers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed6c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "train_model(model_lc, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f439f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "X_pred = torch.linspace(-3.5, 3.5, 100).reshape(-1, 1)\n",
    "with torch.no_grad():\n",
    "    y_pred_lc = model_lc(X_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b27a2f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, y, color='black', label=\"Data\", zorder=3)\n",
    "plt.plot(X_pred, y_pred_lc, label=\"ANN model\", linestyle='dotted', color='red', linewidth=2)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"High capcity ANN model prediction\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3748a012",
   "metadata": {},
   "source": [
    "### Compare the two models' parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325dbec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute mean and standard deviation of model parameters\n",
    "def compute_param_stats(model):\n",
    "    all_params = torch.cat([param.view(-1) for param in model.parameters()])\n",
    "    mean_val = all_params.mean().item()\n",
    "    std_val = all_params.std().item()\n",
    "    min_val = all_params.min().item()\n",
    "    max_val = all_params.max().item()\n",
    "    return mean_val, std_val, min_val, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ccee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistics for each model\n",
    "mean_hc, std_hc, min_hc, max_hc= compute_param_stats(model_hc)\n",
    "mean_lc, std_lc, min_lc, max_lc = compute_param_stats(model_lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e79c854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print(f\"Model with high capcaity: Min = {min_hc:.5f}, Max = {max_hc:.5f} Std = {std_hc:.5f}\")\n",
    "print(f\"Model with low capacity: Min = {min_lc:.5f}, Max = {max_lc:.5f} Std = {std_lc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2f398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract weights for visualization\n",
    "def get_model_weights(model):\n",
    "    return torch.cat([param.view(-1) for param in model.parameters()]).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a405f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract weights from each model\n",
    "weights_hc = get_model_weights(model_hc)\n",
    "weights_lc = get_model_weights(model_lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d0e45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare box plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=[weights_hc, weights_lc], \n",
    "            palette=[\"red\", \"blue\"])\n",
    "plt.xticks([0, 1], [\"High capcity\", \"Low capacity\"])\n",
    "plt.ylabel(\"Weight Values\")\n",
    "plt.title(\"Box Plot of Model Weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c53525",
   "metadata": {},
   "source": [
    "### How to \"tame\" the high capcity model through the weights? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8badc0d",
   "metadata": {},
   "source": [
    "Use sum of the weights:\n",
    "\n",
    "$$\n",
    " \\sum_{j=1}^{n} |w_j|\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "𝑤  are the model weights,\n",
    "𝑛 is the number of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baac4c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of the weights\n",
    "sum(param.abs().sum() for param in model_hc.parameters()).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25243bc5",
   "metadata": {},
   "source": [
    "Ore use sum of the squared weights:\n",
    "\n",
    "$$\n",
    " \\sum_{j=1}^{n} w_j^2\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "𝑤  are the model weights,\n",
    "𝑛 is the number of weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678f4007",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(param.norm(2) for param in model_hc.parameters()).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7d5ba0",
   "metadata": {},
   "source": [
    "### Aussmption \n",
    "We wish to diminish the variation of the model weights. \n",
    "Let's use the above indicator as a penalty in the defined `Loss` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf2c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.005\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model_hc.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5778992",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty = sum(param.norm(2) for param in model_hc.parameters()).item()\n",
    "print(penalty)\n",
    "# But update it in every training iteration according to the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6475b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty_weight = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd153a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model with optional regularization\n",
    "def train_model(model, X, y, epochs=2000, lr=0.005, batch_size=5):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X, y)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(batch_X)\n",
    "            loss = criterion(y_pred, batch_y)\n",
    "            penalty = sum(param.norm(2) for param in model.parameters())\n",
    "            loss += penalty_weight * penalty\n",
    "\n",
    "            # Backpropagation \n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b861f64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different architectures\n",
    "hidden_layers = [32] * 5\n",
    "model_hc_penalty = ANN(hidden_layers=hidden_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672bdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models \n",
    "# loss, penalty = train_model(model_hc_penalty, X_train, y_train)\n",
    "train_model(model_hc_penalty, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7820f64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "X_pred = torch.linspace(-3.5, 3.5, 100).reshape(-1, 1)\n",
    "with torch.no_grad():\n",
    "    y_pred_hc_penalty = model_hc_penalty(X_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4083f3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, y, color='black', label=\"Data\", zorder=3)\n",
    "plt.plot(X_pred, y_pred_hc, label=\"High capacity ANN model\", linestyle='dotted', color='red', linewidth=2)\n",
    "plt.plot(X_pred, y_pred_hc_penalty, label=\"ANN model with extra loss penalty\", color='blue', linewidth=2)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"High capcity ANN model prediction\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb74c734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract weights from THE model\n",
    "weights_hc_penalty = get_model_weights(model_hc_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e942e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare box plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=[weights_hc, weights_hc_penalty], \n",
    "            palette=[\"red\", \"blue\"])\n",
    "plt.xticks([0, 1], [\"High capcity model\", \"High capacity model with penalty\"])\n",
    "plt.ylabel(\"Weight Values\")\n",
    "plt.title(\"Box Plot of Model Weights\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IF_HydroSim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
