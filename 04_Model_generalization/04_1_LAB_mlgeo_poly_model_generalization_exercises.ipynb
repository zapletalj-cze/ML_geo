{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___\n",
    "\n",
    "# [ Machine Learning in Geosciences ]\n",
    "\n",
    "**Department of Applied Geoinformatics and Carthography, Charles University** \n",
    "\n",
    "*Lukas Brodsky lukas.brodsky@natur.cuni.cz*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial model generalization exercises\n",
    "\n",
    "Tasks: \n",
    "\n",
    "1. Evaluate infulence of the training data size on model generalization. \n",
    "\n",
    "2. Evaluate infulence of data noise on the model generalization. \n",
    "\n",
    "3. Generalize the polynomial model by simplification from high degree (top-down approach).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "\n",
    "pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data \n",
    "def fun(x, noise):\n",
    "    \"\"\"Underlying function\"\"\"\n",
    "    return .6 * np.sin(x*6) + x + (x ** .8) * noise\n",
    "\n",
    "# Generate training & testing data\n",
    "def train_test_data(n_samples, noise_factor): \n",
    "    \"\"\"Function to generate training and testing sets\"\"\"\n",
    "    \n",
    "    # train \n",
    "    np.random.seed(0)\n",
    "    X_train = np.sort(np.random.rand(n_samples))\n",
    "    noise_train = np.random.rand(n_samples) * noise_factor\n",
    "    y_train = fun(X_train, noise_train) \n",
    "    X_train = X_train.reshape(-1, 1)\n",
    "    \n",
    "    # test \n",
    "    X_test = np.sort(np.random.rand(n_samples))\n",
    "    noise_test = np.random.rand(n_samples) * noise_factor\n",
    "    y_test = fun(X_test, noise_test)\n",
    "    X_test = X_test.reshape(-1, 1)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data \n",
    "n_samples = 10\n",
    "noise_factor = 0.9\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_data(n_samples, noise_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Underlaying function\n",
    "X_fun = np.linspace(0, 1, 100)\n",
    "noise_fun = np.ones(100) / 2. * noise_factor\n",
    "y_fun = fun(X_fun, noise_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data and underlaying function \n",
    "pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit polynomial model (degree = 10)\n",
    "pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model - training error \n",
    "pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error \n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How well is the model generlized? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the model with the data? \n",
    "pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 1:** Evaluate the infulence of the data size on model generalization\n",
    "* Increse the parameter `n_samples` from 10 to 50, 100, 200, and 500\n",
    "* What is the effect of training data size on its model performance while using model of higher degree than needed? \n",
    "* How importan is to have enough samples? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set size of the samples\n",
    "# train model \n",
    "# evaluate model  \n",
    "noise_factor = 0.9\n",
    "degree = 10\n",
    "n_samples = 10 # update \n",
    "pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the model\n",
    "pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the effect of incresing sample size on model generalization? \n",
    "# Is there any use of the polynomial model for this use case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 2:** Evaluate the infulence of noise on the model generalization\n",
    "* Decrese the noise parameter `noise_factor` from 0.9 to 0.5, and 0.1\n",
    "* What is the effect of noise in the training data on model generalization? \n",
    "* Next, increase  the parameter `n_samples` from to 200 and keep `noise_factor` at 10% = 0.1. How does the model look?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_factor = 0.9\n",
    "degree = 10\n",
    "n_samples = 20 \n",
    "\n",
    "# run the model \n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the model\n",
    "pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 3:** Simplify the model for better generalization\n",
    "* Decrese the degree of polynomial of model`deg` from 10 to reasonable number, so the difference between testing and training model is minimized. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_factor = 0.5\n",
    "degree = 10\n",
    "n_samples = 30 \n",
    "# run the model \n",
    "pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the model\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
